{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99596f2",
   "metadata": {},
   "source": [
    "#  Part 4 : Similarity Network Fusion with Graph Convolutional Networks\n",
    "\n",
    "In the previous notebook we trained a Graph Convolutional Network on two similarity matrices. We found that when our network is bad, our performance is bad. When we have a more informative network we can improve this performance. \n",
    "\n",
    "Neither of our networks were more expressive than performing a basic linear regression however. We are not fully leveraging the power of neworks, in particular their flexibility. \n",
    "\n",
    "In this notebook we will use the Similarity Network Fusion (SNF) algorithm to integrate a second modality.\n",
    "\n",
    "In this part we will : \n",
    "- Create a second patient similarity network \n",
    "- Train a quick GCN on this modality to test it's accuracy\n",
    "- Perform SNF to integrate our two modalities\n",
    "- Retrain a GCN on the combined network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d728e",
   "metadata": {},
   "source": [
    "## Import Functions and Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee51ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from palettable import wesanderson\n",
    "import snf\n",
    "import sys\n",
    "sys.path.insert(0 , '/tutorial/')\n",
    "from functions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4558ad",
   "metadata": {},
   "source": [
    "## Import and Process Generation Scotland Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/intermediate/GCN_Data.pkl' , 'rb') as file : \n",
    "    loaded_data = pd.read_pickle(file)\n",
    "\n",
    "phenotypes = loaded_data['phenotypes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beed0b7",
   "metadata": {},
   "source": [
    "## Create Patient Similarity Network for Second Modality\n",
    "\n",
    "### NOTE : Creating second modality of time since last cigarette. This will be highly correlated with the outcome of smoking or not however, we want to use this as an exemplar for SNF + GNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def time_since_last_smoked(row) : \n",
    "    if row['pack_years'] == 0 : \n",
    "        return row['age']\n",
    "    else :\n",
    "        if row.isna()['stopped'] :\n",
    "            return 0\n",
    "        else : \n",
    "            return row['stopped']\n",
    "        \n",
    "phenotypes['time_since_last_smoked'] = phenotypes.apply(time_since_last_smoked , axis =1)\n",
    "\n",
    "'''\n",
    "#################################################\n",
    "                YOUR CODE HERE\n",
    "#################################################\n",
    "Plot the distribution of the Time Since Last Cigarette Phenotype\n",
    "'''\n",
    "\n",
    "plt.title('Distribution of Time Since Last Cigarette')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119d139-b5f4-49f6-9d4d-b81d3444a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#################################################\n",
    "                YOUR CODE HERE\n",
    "#################################################\n",
    "Here we will infer a similarity between patients based on their time since last cigarette\n",
    "In order to calculate this we will \n",
    "\n",
    "1. Scale the data using the MinMaxScaler\n",
    "2. Create an empty nxn dataframe of zeros with the patients on the index and columns\n",
    "3. Fill the dataframe on the euclidean distance between each patients time_since_last_smoked \n",
    "\n",
    "'''\n",
    "scaler = MinMaxScaler()\n",
    "scaled_time = scaler.fit_transform().reshape(1,-1)[0]\n",
    "\n",
    "n = \n",
    "# Create a DataFrame filled with zeros\n",
    "df = pd.DataFrame(np.zeros() , columns= , index=)\n",
    "\n",
    "# Fill the DataFrame with the differences\n",
    "for i, integer in enumerate(scaled_time):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55483c-f311-4b68-9cac-85e72c0553c6",
   "metadata": {},
   "source": [
    "### Plot the Time Since Last Smoked Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05121b71-adc2-4c08-b398-3770d4a1f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_colour = phenotypes['Smoking'].astype('category').cat.set_categories(wesanderson.FantasticFox2_5.hex_colors , rename=True)\n",
    "\n",
    "print(f\"{phenotypes['Smoking'].astype('category').cat.categories[0]} : 0 \\n{phenotypes['Smoking'].astype('category').cat.categories[1]} : 1\")\n",
    "\n",
    "G_time_to_smoke = plot_knn_network(df , 25 , phenotypes['Smoking'] , node_colours=node_colour)\n",
    "plt.title('Time Since Last Cigarette Patient Similarity Network')\n",
    "legend_handles = gen_graph_legend(node_colour , G_time_to_smoke , 'label')\n",
    "plt.legend(handles = legend_handles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9581646",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> Train GCN on second modality for comparison of performance </font>\n",
    "\n",
    "Here we will re-use the code from the previous section, specifically the train and evaluate functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c97b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.from_networkx(G_time_to_smoke , node_attrs=['idx' , 'label']) # Convert networkx graph to dgl graph\n",
    "g.ndata['feat'] = torch.Tensor(loaded_data['Feat'].iloc[g.ndata['idx'].numpy()].values) # Add node features to graph\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available\n",
    "\n",
    "g = g.to(device) # Move graph to device\n",
    "\n",
    "node_subjects = phenotypes['Smoking'].iloc[g.ndata['idx'].detach().cpu().numpy()].reset_index(drop=True) # Get node target labels from meta data\n",
    "node_subjects.name = 'Smoking'\n",
    "\n",
    "train_tmp_index , test_index = train_test_split(                 # Split data into temporary training and testing sets\n",
    "    node_subjects.index, train_size=0.6, stratify=node_subjects\n",
    "    )\n",
    "train_index , val_index = train_test_split(                       # Split temporary training data into training and validation sets\n",
    "    train_tmp_index, train_size=0.8, stratify=node_subjects.loc[train_tmp_index]\n",
    "    )\n",
    "\n",
    "GCN_input_shapes = g.ndata['feat'].shape[1] # Get input shape for GCN\n",
    "\n",
    "labels = F.one_hot(g.ndata['label'].to(torch.int64)) #  One hot encode labels\n",
    "\n",
    "output_metrics = []\n",
    "logits = np.array([])\n",
    "labels_all = np.array([])\n",
    "\n",
    "model = GCN(GCN_input_shapes , [128], len(node_subjects.unique())).to(device)  # Create GCN model\n",
    "print(model)\n",
    "print(g)\n",
    "\n",
    "loss_plot = train(g, g.ndata['feat'] , train_index , val_index , device ,  model , labels , 1200 , 1e-3) # Train model\n",
    "plt.show()\n",
    "\n",
    "test_output_metrics = evaluate(test_index , device , g , g.ndata['feat'] , model , labels ) # Evaluate model on test set\n",
    "\n",
    "print(\n",
    "    \"GNN Model | Test Accuracy = {:.4f} | F1 = {:.4f} |\".format(\n",
    "     test_output_metrics[1] , test_output_metrics[2] )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a8df4",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> Similarity Network Fusion (SNF) </font>\n",
    "\n",
    "We will once again implement SNF from the paper by [Wang et al.](https://www.nature.com/articles/nmeth.2810)\n",
    "\n",
    "We will implement it using the python package [snfpy](https://pypi.org/project/snfpy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18412f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#################################################\n",
    "                YOUR CODE HERE\n",
    "#################################################\n",
    "\n",
    "We need to create a list with all the graphs we want to include in SNF.\n",
    "In this section you will need to : \n",
    "    1. Convert the graphs into pandas adjacency matrices hint : use nx.to_pandas_adjacency()\n",
    "    2. Append the adjacency matrices to the list.\n",
    "\n",
    "'''\n",
    "G_DNAm = loaded_data['PSN_EWAS']\n",
    "full_graphs = []\n",
    "\n",
    "for graph in [G_time_to_smoke , G_DNAm] : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#################################################\n",
    "                YOUR CODE HERE\n",
    "#################################################\n",
    "\n",
    "Here we will perform SNF to fuse our two modalities of data.\n",
    "\n",
    "1. Use the SNF function from the snf package to fuse the graphs in full_graphs. Use k = 25 and t = 10.\n",
    "2. Convert the numpy array output from the SNF function to a pandas DataFrame with the index and columns as the patient IDs.\n",
    "\n",
    "'''\n",
    "adj = snf.snf()\n",
    "\n",
    "adj_snf = pd.DataFrame(data=adj , index=phenotypes.index , columns=phenotypes.index) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0cfb1",
   "metadata": {},
   "source": [
    "Note that SNF returns a fully connected graph. We will sparsify the edges by performing KNN based on the similarity weights from SNF\n",
    "\n",
    "We have provided this functionality previously in the plot_knn_network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eece5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_colour = phenotypes.loc[adj_snf.index]['Smoking'].astype('category').cat.set_categories(wesanderson.FantasticFox2_5.hex_colors , rename=True) # Set node colours\n",
    "\n",
    "G = plot_knn_network(adj_snf, k , phenotypes['Smoking'] , node_colours=node_colour)  # Plot the fused network and get back networkx graph\n",
    "plt.title('Fused Patient Similarity Network')\n",
    "legend_handles = gen_graph_legend(node_colour , G , 'label') # Generate legend\n",
    "plt.legend(handles = legend_handles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38766aa",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> GCN on SNF network </font>\n",
    "\n",
    "We now have fused our graphs into a single patient similarity network and we are ready to learn from this. \n",
    "\n",
    "Again we will re-use the code from the previous part but changing our graph to the the SNF graph created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.from_networkx(G , node_attrs=['idx' , 'label']) # Convert networkx graph to dgl graph\n",
    "g.ndata['feat'] = torch.Tensor(loaded_data['Feat'].iloc[g.ndata['idx'].numpy()].values) # Add node features to graph\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available\n",
    "\n",
    "g = g.to(device) # Move graph to device\n",
    "\n",
    "node_subjects = phenotypes['Smoking'].iloc[g.ndata['idx'].detach().cpu().numpy()].reset_index(drop=True) # Get node target labels from meta data\n",
    "node_subjects.name = 'Smoking'\n",
    "\n",
    "train_tmp_index , test_index = train_test_split(                # Split data into temporary training and testing sets\n",
    "    node_subjects.index, train_size=0.6, stratify=node_subjects\n",
    "    )\n",
    "train_index , val_index = train_test_split(                     # Split temporary training data into training and validation sets\n",
    "    train_tmp_index, train_size=0.8, stratify=node_subjects.loc[train_tmp_index]\n",
    "    )\n",
    "\n",
    "GCN_input_shapes = g.ndata['feat'].shape[1]  # Get input shape for GCN\n",
    "\n",
    "labels = F.one_hot(g.ndata['label'].to(torch.int64)) # One hot encode labels\n",
    "\n",
    "output_metrics = []\n",
    "logits = np.array([])\n",
    "labels_all = np.array([])\n",
    "\n",
    "model = GCN(GCN_input_shapes , [128], len(node_subjects.unique())).to(device)  # Create GCN model\n",
    "print(model)\n",
    "print(g)\n",
    "\n",
    "loss_plot = train(g, g.ndata['feat'] , train_index , val_index , device ,  model , labels , 1200 , 1e-3) # Train model\n",
    "plt.show()\n",
    "\n",
    "test_output_metrics = evaluate(test_index , device , g , g.ndata['feat'] , model , labels ) # Evaluate model on test set\n",
    "\n",
    "print(\n",
    "    \"GNN Model | Test Accuracy = {:.4f} | F1 = {:.4f} |\".format(\n",
    "     test_output_metrics[1] , test_output_metrics[2] )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Barry ISMB Env",
   "language": "python",
   "name": "bryanismb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}